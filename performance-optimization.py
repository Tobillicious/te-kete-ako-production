#!/usr/bin/env python3
"""
Performance Optimization - Push Lighthouse Scores to 90+
Analyzes and fixes performance bottlenecks to improve Lighthouse metrics

Current Lighthouse Scores (from GraphRAG):
- Overall: 91.4/100 ‚úÖ (already excellent)
- Performance: 85/100 ‚ö†Ô∏è (target: 90+)
- Accessibility: 96/100 ‚úÖ (excellent)
- SEO: 94/100 ‚úÖ (excellent)
- PWA: 88/100 ‚ö†Ô∏è (target: 90+)
- Best Practices: 94/100 ‚úÖ (excellent)

Focus: Improve Performance and PWA scores
"""

import os
import re
from pathlib import Path

def analyze_performance_bottlenecks():
    """Analyze common performance issues"""

    public_dir = Path('public')
    html_files = list(public_dir.rglob('*.html'))

    performance_issues = {
        'large_html_files': [],
        'multiple_js_includes': [],
        'inline_styles': [],
        'missing_lazy_loading': [],
        'large_css_files': [],
        'unused_components': []
    }

    print(f"üîç Analyzing performance across {len(html_files)} HTML files...")

    for html_file in html_files:
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()

            file_size = len(content)

            # Check for large HTML files (>500 lines)
            if file_size > 500 * 100:  # Rough estimate: 500 lines * 100 chars per line
                performance_issues['large_html_files'].append(str(html_file))

            # Check for multiple JavaScript includes
            js_includes = len(re.findall(r'<script[^>]*src=', content))
            if js_includes > 10:
                performance_issues['multiple_js_includes'].append((str(html_file), js_includes))

            # Check for inline styles (could be moved to CSS)
            inline_styles = len(re.findall(r'style="[^"]*"', content))
            if inline_styles > 20:
                performance_issues['inline_styles'].append((str(html_file), inline_styles))

            # Check for missing lazy loading on images
            if re.search(r'<img', content) and not re.search(r'loading="lazy"', content):
                performance_issues['missing_lazy_loading'].append(str(html_file))

        except Exception as e:
            print(f"‚ùå Error analyzing {html_file}: {e}")

    return performance_issues

def optimize_large_html_files():
    """Optimize large HTML files by moving content to components"""

    print("üîß Optimizing large HTML files...")

    large_files = [
        'public/index.html',
        'public/mathematics-hub.html',
        'public/cultural-learning.html'
    ]

    optimizations = []

    for file_path in large_files:
        try:
            file_path = Path(file_path)
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Look for sections that could be moved to components
                # For example, large inline content sections
                sections_to_extract = []

                # Find large content sections that could be components
                section_patterns = [
                    (r'<!-- üèÜ FEATURED[^>]*>[\s\S]*?<!-- End[^>]*>', 'featured-section'),
                    (r'<!-- üåü[^>]*>[\s\S]*?<!-- End[^>]*>', 'excellence-section'),
                    (r'<!-- üéØ[^>]*>[\s\S]*?<!-- End[^>]*>', 'pathways-section'),
                ]

                for pattern, section_name in section_patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        for i, match in enumerate(matches):
                            if len(match) > 1000:  # Large section
                                sections_to_extract.append({
                                    'file': str(file_path),
                                    'section': section_name,
                                    'content': match,
                                    'size': len(match)
                                })

                if sections_to_extract:
                    optimizations.append({
                        'file': str(file_path),
                        'sections': sections_to_extract
                    })

        except Exception as e:
            print(f"‚ùå Error optimizing {file_path}: {e}")

    return optimizations

def add_performance_headers():
    """Add performance optimization headers to HTML files"""

    public_dir = Path('public')
    html_files = list(public_dir.rglob('*.html'))

    print("üîß Adding performance optimization headers...")

    performance_headers = '''<!-- Performance Optimizations -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
<meta name="format-detection" content="telephone=no">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="theme-color" content="#1a4d2e">

<!-- DNS Prefetch for external resources -->
<link rel="dns-prefetch" href="//fonts.googleapis.com">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net">

<!-- Preconnect for critical resources -->
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>

<!-- Resource hints -->
<link rel="preload" href="/css/professionalization-system.css" as="style">
<link rel="preload" href="/js/component-loader.js" as="script">'''

    optimized_files = 0

    for html_file in html_files[:50]:  # Start with first 50 files
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Only add to files that don't already have these optimizations
            if 'dns-prefetch' not in content:
                # Find where to insert (after viewport meta)
                insert_pattern = r'(<meta[^>]*name=["\']viewport["\'][^>]*>)'

                if re.search(insert_pattern, content):
                    content = re.sub(insert_pattern, r'\1\n' + performance_headers, content)

                    with open(html_file, 'w', encoding='utf-8') as f:
                        f.write(content)

                    optimized_files += 1

        except Exception as e:
            print(f"‚ùå Error optimizing {html_file}: {e}")

    return optimized_files

def main():
    """Run performance optimizations"""

    print("‚ö° PERFORMANCE OPTIMIZATION - Push to 90+ Lighthouse")
    print("=" * 60)

    # Analyze current bottlenecks
    print("üîç Analyzing performance bottlenecks...")
    issues = analyze_performance_bottlenecks()

    print("\nüìä PERFORMANCE ISSUES FOUND:")
    print("=" * 60)
    print(f"üìÑ Large HTML Files (>500 lines): {len(issues['large_html_files'])}")
    print(f"üìú Multiple JS Includes (>10): {len(issues['multiple_js_includes'])}")
    print(f"üé® Inline Styles (>20): {len(issues['inline_styles'])}")
    print(f"üñºÔ∏è  Missing Lazy Loading: {len(issues['missing_lazy_loading'])}")

    if issues['large_html_files']:
        print("\nüìÑ Largest HTML Files:")
        for file in issues['large_html_files'][:5]:
            print(f"   - {file}")

    # Add performance headers
    print("\nüîß Adding performance optimization headers...")
    optimized = add_performance_headers()
    print(f"‚úÖ Added performance headers to {optimized} files")

    # Optimize large files
    print("\nüîß Optimizing large HTML files...")
    optimizations = optimize_large_html_files()

    if optimizations:
        print(f"üì¶ Found {sum(len(opt['sections']) for opt in optimizations)} large sections that could be components")
        for opt in optimizations:
            print(f"   üìÑ {opt['file']}: {len(opt['sections'])} sections")

    print("\nüöÄ PERFORMANCE OPTIMIZATION COMPLETE!")
    print("   - Added resource hints (DNS prefetch, preconnect)")
    print("   - Added performance meta tags")
    print("   - Identified large files for component extraction")
    print("   - Analyzed JavaScript loading patterns")
    print("\nüéØ RECOMMENDED NEXT STEPS:")
    print("   1. Extract large inline sections to components")
    print("   2. Add lazy loading to remaining images")
    print("   3. Optimize JavaScript loading order")
    print("   4. Consider code splitting for large JS files")

if __name__ == '__main__':
    main()
