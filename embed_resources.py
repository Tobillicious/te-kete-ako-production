#!/usr/bin/env python3
"""
Te Kete Ako - GraphRAG Phase 1: Resource Embedding Generation
Creates vector embeddings for all educational resources to enable semantic search.
"""

import os
import sys
from supabase import create_client, Client
from sentence_transformers import SentenceTransformer
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Supabase configuration
SUPABASE_URL = 'https://nlgldaqtubrlcqddppbq.supabase.co'
SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5sZ2xkYXF0dWJybGNxZGRwcGJxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTMwODkzMzksImV4cCI6MjA2ODY2NTMzOX0.IFaWqep1MBSofARiCUuzvAReC44hwGnmKOMNSd55nIM'

def create_embeddings():
    """Generate and store embeddings for all educational resources."""
    
    logger.info("üöÄ Starting Te Kete Ako Resource Embedding Process...")
    
    # Initialize Supabase client
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        logger.info("‚úÖ Connected to Supabase")
    except Exception as e:
        logger.error(f"‚ùå Failed to connect to Supabase: {e}")
        return False
    
    # Load the embedding model
    try:
        logger.info("üì• Loading sentence-transformers model...")
        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        logger.info("‚úÖ Model loaded successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to load model: {e}")
        return False
    
    # Fetch all resources
    try:
        logger.info("üìö Fetching all educational resources...")
        response = supabase.table('resources').select('id, title, description, type, path').execute()
        
        if not response.data:
            logger.warning("‚ö†Ô∏è No resources found in database")
            return False
            
        resources = response.data
        logger.info(f"üìä Found {len(resources)} resources to process")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to fetch resources: {e}")
        return False
    
    # Process each resource
    success_count = 0
    error_count = 0
    
    for i, resource in enumerate(resources, 1):
        try:
            resource_id = resource['id']
            title = resource.get('title', '')
            description = resource.get('description', '')
            resource_type = resource.get('type', '')
            path = resource.get('path', '')
            
            # Create comprehensive text for embedding
            # Combine title, description, type, and path for rich semantic understanding
            content_parts = [
                f"Title: {title}",
                f"Description: {description}",
                f"Type: {resource_type}",
                f"Subject area: {extract_subject_from_path(path)}"
            ]
            
            # Add cultural context markers
            cultural_markers = extract_cultural_markers(title, description)
            if cultural_markers:
                content_parts.append(f"Cultural elements: {cultural_markers}")
            
            content_text = " | ".join(filter(None, content_parts))
            
            logger.info(f"üîÑ Processing ({i}/{len(resources)}): {title[:50]}...")
            
            # Generate embedding
            embedding = model.encode(content_text).tolist()
            
            # Check if embedding already exists
            existing = supabase.table('resource_embeddings').select('id').eq('resource_id', resource_id).execute()
            
            if existing.data:
                # Update existing embedding
                result = supabase.table('resource_embeddings').update({
                    'embedding': embedding
                }).eq('resource_id', resource_id).execute()
                logger.info(f"üîÑ Updated embedding for: {title[:30]}")
            else:
                # Insert new embedding
                result = supabase.table('resource_embeddings').insert({
                    'resource_id': resource_id,
                    'embedding': embedding
                }).execute()
                logger.info(f"‚úÖ Created embedding for: {title[:30]}")
            
            success_count += 1
            
        except Exception as e:
            logger.error(f"‚ùå Error processing resource {resource.get('title', 'Unknown')}: {e}")
            error_count += 1
            continue
    
    # Final report
    logger.info("=" * 60)
    logger.info(f"üéâ Embedding Generation Complete!")
    logger.info(f"‚úÖ Successfully processed: {success_count} resources")
    logger.info(f"‚ùå Errors encountered: {error_count} resources")
    logger.info(f"üìä Total resources: {len(resources)}")
    logger.info("=" * 60)
    
    return error_count == 0

def extract_subject_from_path(path):
    """Extract subject area from file path for better categorization."""
    if not path:
        return ""
    
    path_lower = path.lower()
    
    # Map path patterns to subjects
    subject_mappings = {
        'te-reo': 'Te Reo MƒÅori',
        'maori': 'Te Ao MƒÅori',
        'haka': 'Cultural Studies',
        'treaty': 'New Zealand History',
        'waitangi': 'New Zealand History',
        'writers-toolkit': 'English Writing',
        'peel': 'English Writing',
        'math': 'Mathematics',
        'science': 'Science',
        'social': 'Social Studies',
        'y8-systems': 'Social Studies Systems',
        'games': 'Interactive Learning',
        'handouts': 'Learning Resources'
    }
    
    for keyword, subject in subject_mappings.items():
        if keyword in path_lower:
            return subject
    
    return "General Education"

def extract_cultural_markers(title, description):
    """Identify cultural elements for enhanced semantic understanding."""
    text = f"{title} {description}".lower()
    
    cultural_keywords = [
        'mƒÅori', 'maori', 'te reo', 'whakapapa', 'haka', 'marae', 'iwi',
        'tangata whenua', 'tino rangatiratanga', 'kaitiakitanga', 'manaakitanga',
        'treaty of waitangi', 'te tiriti', 'cultural', 'indigenous', 'traditional',
        'karakia', 'hongi', 'powhiri', 'whakataukƒ´'
    ]
    
    found_markers = [keyword for keyword in cultural_keywords if keyword in text]
    return ", ".join(found_markers) if found_markers else ""

if __name__ == "__main__":
    print("üåü Te Kete Ako - GraphRAG Phase 1: Resource Embeddings")
    print("=" * 60)
    
    # Check dependencies
    try:
        import sentence_transformers
        import supabase
        print("‚úÖ All dependencies available")
    except ImportError as e:
        print(f"‚ùå Missing dependency: {e}")
        print("Please install: pip install sentence-transformers supabase")
        sys.exit(1)
    
    # Run embedding generation
    success = create_embeddings()
    
    if success:
        print("üéâ GraphRAG Phase 1 foundation complete!")
        print("Next steps:")
        print("1. Create the match_resources SQL function")
        print("2. Build the find-similar-resources Edge Function")
        print("3. Implement frontend semantic search")
    else:
        print("‚ùå Embedding generation failed. Check logs above.")
        sys.exit(1)