#!/usr/bin/env python3
"""
UPLOAD TO SUPABASE GRAPHRAG
Batch upload 6,596 resources + 566,852 relationships
"""

import json
import os
import time

print("ðŸš€ UPLOADING TO SUPABASE GRAPHRAG")
print("=" * 70)

# Check for Supabase package
try:
    from supabase import create_client
    HAS_SUPABASE = True
except ImportError:
    print("âš ï¸  supabase-py not installed. Installing...")
    os.system("pip3 install supabase")
    from supabase import create_client
    HAS_SUPABASE = True

# Configuration
SUPABASE_URL = "https://nlgldaqtubrlcqddppbq.supabase.co"
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or os.getenv("SUPABASE_ANON_KEY") or ""

if not SUPABASE_KEY:
    print("\nâš ï¸  SUPABASE_KEY not found in environment")
    print("ðŸ“‹ To upload, you need to:")
    print("   1. Get anon key from Supabase dashboard")
    print("   2. Set environment variable: export SUPABASE_KEY=your_key")
    print("   3. Run this script again")
    print("\nðŸ“ Alternatively, upload manually:")
    print("   1. Open: https://nlgldaqtubrlcqddppbq.supabase.co")
    print("   2. SQL Editor â†’ Run graphrag-upload.sql")
    print("   3. Table Editor â†’ Import JSON files")
    print("\nðŸ’¾ Data is ready in:")
    print("   â€¢ graphrag-resources-upload.json (6,596 resources)")
    print("   â€¢ graphrag-relationships-upload.json (566,852 relationships)")
    exit(0)

# Connect to Supabase
print("\nðŸ”Œ Connecting to Supabase...")
try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("   âœ… Connected!")
except Exception as e:
    print(f"   âŒ Connection failed: {e}")
    exit(1)

# Create tables first
print("\nðŸ—ƒï¸  Creating tables...")
with open('graphrag-upload.sql', 'r') as f:
    sql = f.read()
    # Note: Table creation might need to be done via dashboard
    print("   â„¹ï¸  Tables defined in graphrag-upload.sql")
    print("   ðŸ“‹ Run that SQL in Supabase dashboard first if tables don't exist")

# Load data
print("\nðŸ“Š Loading data...")
with open('graphrag-resources-upload.json', 'r') as f:
    resources = json.load(f)
print(f"   âœ… {len(resources):,} resources loaded")

with open('graphrag-relationships-upload.json', 'r') as f:
    relationships = json.load(f)
print(f"   âœ… {len(relationships):,} relationships loaded")

# Upload resources in batches
print("\nðŸ“¤ Uploading resources (batch size: 100)...")
BATCH_SIZE = 100
uploaded_resources = 0

for i in range(0, len(resources), BATCH_SIZE):
    batch = resources[i:i+BATCH_SIZE]
    
    try:
        response = supabase.table('graphrag_resources').upsert(batch).execute()
        uploaded_resources += len(batch)
        
        if (i + BATCH_SIZE) % 500 == 0:
            print(f"   ... {uploaded_resources:,} / {len(resources):,} resources")
        
        time.sleep(0.1)  # Rate limiting
        
    except Exception as e:
        print(f"   âš ï¸  Batch {i//BATCH_SIZE + 1} failed: {e}")
        continue

print(f"   âœ… Uploaded {uploaded_resources:,} resources")

# Upload relationships in batches
print("\nðŸ“¤ Uploading relationships (batch size: 1000)...")
BATCH_SIZE = 1000
uploaded_relationships = 0

for i in range(0, len(relationships), BATCH_SIZE):
    batch = relationships[i:i+BATCH_SIZE]
    
    try:
        response = supabase.table('graphrag_relationships').insert(batch).execute()
        uploaded_relationships += len(batch)
        
        if (i + BATCH_SIZE) % 10000 == 0:
            print(f"   ... {uploaded_relationships:,} / {len(relationships):,} relationships")
        
        time.sleep(0.05)  # Rate limiting
        
    except Exception as e:
        print(f"   âš ï¸  Batch {i//BATCH_SIZE + 1} failed: {e}")
        continue

print(f"   âœ… Uploaded {uploaded_relationships:,} relationships")

print("\n" + "=" * 70)
print("ðŸŽ‰ GRAPHRAG UPLOAD COMPLETE!")
print("=" * 70)
print(f"""
ðŸ“Š Uploaded:
   â€¢ {uploaded_resources:,} resources
   â€¢ {uploaded_relationships:,} relationships
   
ðŸ” Now you can query:
   SELECT * FROM graphrag_resources WHERE quality_score >= 90;
   SELECT * FROM graphrag_relationships WHERE relationship_type = 'prerequisite';
   
ðŸŽ¯ Knowledge graph is LIVE and queryable!
""")

